{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883e7fb7-3f53-491f-8c37-7dfa6f9f131f",
   "metadata": {},
   "source": [
    "## Project Description: Next Word Prediction Using GRU RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22563f88-d2a2-4348-8541-ff5b1cf99924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import nltk\n",
    "import  pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout,GRU\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99cf44e-9234-4eb8-b481-9ebeab55ba17",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb1981c9-47e6-43f4-8745-97bd091ce3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word is : 4818\n"
     ]
    }
   ],
   "source": [
    "# Laod the dataset\n",
    "with open('hamlet.txt','r') as file:\n",
    "    text=file.read().lower()\n",
    "\n",
    "# Tokenize the text-creating indexes for words\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words=len(tokenizer.word_index)+1\n",
    "print(f\"Total word is : {total_words}\")\n",
    "\n",
    "# create input sequences\n",
    "input_sequences=[]\n",
    "for line in text.split('\\n'):\n",
    "    token_list=tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1,len(token_list)):\n",
    "        n_gram_sequence=token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad Sequences\n",
    "max_sequence_len=max([len(x) for x in input_sequences])\n",
    "\n",
    "# Padding input sequences\n",
    "input_sequences=np.array(pad_sequences(input_sequences,maxlen=max_sequence_len,padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c8d9480-9763-42c4-81d2-e48901243658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Features and Label\n",
    "X,y=input_sequences[:,:-1],input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e1f8484-2ae7-418f-ac7c-5f83555c8281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    0,    1],\n",
       "       [   0,    0,    0, ...,    0,    1,  687],\n",
       "       [   0,    0,    0, ...,    1,  687,    4],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  687,    4,   45],\n",
       "       [   0,    0,    0, ...,    4,   45, 1047],\n",
       "       [   0,    0,    0, ...,   45, 1047,    4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c698983-5348-46a6-8c3d-5bb778536afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 687,    4,   45, ..., 1047,    4,  193])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f628e0f-5711-469a-9df4-650bb43d6c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=tf.keras.utils.to_categorical(y,num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89483167-4cc1-49d8-9bc9-959147144bf5",
   "metadata": {},
   "source": [
    "This line converts integer-encoded target labels (y) into one-hot encoded categorical vectors. It transforms each integer label into a binary vector where the index of the target word is marked as 1, and all other indices are 0. The num_classes parameter specifies the total number of unique words in the vocabulary. This is commonly used in neural network classification tasks to prepare target labels for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ff6d360-1b84-416d-80b7-7ae0ecf7e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d197b0b-b39b-41ab-a14f-94aa4739c675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">481,800</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">113,400</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">75,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4818</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">486,618</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │         \u001b[38;5;34m481,800\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m150\u001b[0m)             │         \u001b[38;5;34m113,400\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m150\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m75,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4818\u001b[0m)                │         \u001b[38;5;34m486,618\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,157,418</span> (4.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,157,418\u001b[0m (4.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,157,418</span> (4.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,157,418\u001b[0m (4.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(max_sequence_len,)))  # Input layer\n",
    "model.add(Embedding(input_dim=total_words,  \n",
    "                    output_dim=100))      \n",
    "model.add(GRU(150, return_sequences=True)) \n",
    "model.add(Dropout(0.2))                  \n",
    "model.add(GRU(100))                        \n",
    "model.add(Dense(total_words, activation=\"softmax\"))  \n",
    "\n",
    "# Compile\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57c86df8-96b6-4d17-a6cc-d37ebc167714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.0330 - loss: 7.1689 - val_accuracy: 0.0354 - val_loss: 6.7933\n",
      "Epoch 2/50\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - accuracy: 0.0413 - loss: 6.4715 - val_accuracy: 0.0532 - val_loss: 6.8288\n",
      "Epoch 3/50\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - accuracy: 0.0511 - loss: 6.1828 - val_accuracy: 0.0635 - val_loss: 6.7751\n",
      "Epoch 4/50\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.0676 - loss: 5.9561 - val_accuracy: 0.0764 - val_loss: 6.7993\n",
      "Epoch 5/50\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.0836 - loss: 5.6748 - val_accuracy: 0.0727 - val_loss: 6.9505\n",
      "Epoch 6/50\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.0937 - loss: 5.3971 - val_accuracy: 0.0748 - val_loss: 7.0034\n",
      "Epoch 7/50\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.1048 - loss: 5.1587 - val_accuracy: 0.0738 - val_loss: 7.1008\n",
      "Epoch 8/50\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 27ms/step - accuracy: 0.1204 - loss: 4.9029 - val_accuracy: 0.0721 - val_loss: 7.1980\n",
      "Epoch 9/50\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - accuracy: 0.1380 - loss: 4.6811 - val_accuracy: 0.0725 - val_loss: 7.3217\n",
      "Epoch 10/50\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.1589 - loss: 4.4648 - val_accuracy: 0.0655 - val_loss: 7.4546\n",
      "Epoch 11/50\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.1885 - loss: 4.2591 - val_accuracy: 0.0734 - val_loss: 7.5182\n",
      "Epoch 12/50\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.2105 - loss: 4.0661 - val_accuracy: 0.0655 - val_loss: 7.6578\n",
      "Epoch 13/50\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.2385 - loss: 3.8881 - val_accuracy: 0.0657 - val_loss: 7.7457\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history=model.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test),verbose=1,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0894d832-e907-4ec2-8b06-0874f678ed41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(\"gru_next_word_model.h5\")\n",
    "# Save the tokenizer\n",
    "import pickle\n",
    "with open('tokenizer.pickle','wb') as handle:\n",
    "    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.12.5)",
   "language": "python",
   "name": "3.12.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
